{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliabui/csc408-411/blob/main/CSC411Mod3SpotTheLeakageActivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spot the Leakage\n",
        "\n",
        "There are two lines in this script where we call `.fit(...)` on the entire dataset *before* the train/test split. Those are the \"leaky\" spots\".\n",
        "\n",
        "###Why they're leaky\n",
        "\n",
        "* `StandardScaler().fit(X)` learnes means/SDs from **train + test** --> the test set influences preprocessing\n",
        "\n",
        "* `SelectKBest(...).fit(X_scaled_leaky, y)` is worse: it uses **labels** `y` from the entire dataset to choose features, so the test labels directly shape the features.\n",
        "\n",
        "###How to \"fix\"\n",
        "\n",
        "* **Split first**, then put preprocessing and selection **inside a `Pipeline`** so `.fit(...)` happens only on the training fold."
      ],
      "metadata": {
        "id": "juicku_s2n-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gxJn9GJ2jpC",
        "outputId": "b696a883-7efb-490c-9451-6ca89f076cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LEAKY workflow ===\n",
            "Confusion matrix:\n",
            " [[40  2]\n",
            " [ 8 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.833     0.952     0.889        42\n",
            "           1      0.970     0.889     0.928        72\n",
            "\n",
            "    accuracy                          0.912       114\n",
            "   macro avg      0.902     0.921     0.908       114\n",
            "weighted avg      0.919     0.912     0.913       114\n",
            "\n",
            "ROC AUC: 0.991\n",
            "\n",
            "=== CLEAN pipeline (k=10) ===\n",
            "Confusion matrix:\n",
            " [[40  2]\n",
            " [ 8 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.833     0.952     0.889        42\n",
            "           1      0.970     0.889     0.928        72\n",
            "\n",
            "    accuracy                          0.912       114\n",
            "   macro avg      0.902     0.921     0.908       114\n",
            "weighted avg      0.919     0.912     0.913       114\n",
            "\n",
            "ROC AUC: 0.991\n",
            "\n",
            "Best CV params: {'model__C': 10.0, 'model__penalty': 'l2', 'select__k': 20}\n",
            "Best CV ROC AUC: 0.997\n",
            "\n",
            "=== BEST pipeline (CV-tuned) ===\n",
            "Confusion matrix:\n",
            " [[40  2]\n",
            " [ 4 68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.909     0.952     0.930        42\n",
            "           1      0.971     0.944     0.958        72\n",
            "\n",
            "    accuracy                          0.947       114\n",
            "   macro avg      0.940     0.948     0.944       114\n",
            "weighted avg      0.948     0.947     0.948       114\n",
            "\n",
            "ROC AUC: 0.994\n"
          ]
        }
      ],
      "source": [
        "# Activity 1: Spot the Leakage  ----------------------------------------------\n",
        "# Goal: Identify data leakage (doing preprocessing/feature selection on the FULL dataset\n",
        "# before the split/CV) and fix it with a Pipeline.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "RNG = 42\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 0) Data\n",
        "# ----------------------------------------------------------------------\n",
        "data = load_breast_cancer(as_frame=True)\n",
        "X = data.data\n",
        "y = data.target  # 0/1\n",
        "\n",
        "# Helper for evaluation\n",
        "def evaluate(model, X_train, X_test, y_train, y_test, name=\"model\"):\n",
        "    model.fit(X_train, y_train)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        # for safety; most LR models have predict_proba\n",
        "        y_proba = model.decision_function(X_test)\n",
        "        # rescale to (0,1) if needed (optional)\n",
        "        y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min() + 1e-12)\n",
        "    y_pred = (y_proba >= 0.50).astype(int)\n",
        "\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred, digits=3))\n",
        "    print(\"ROC AUC:\", round(roc_auc_score(y_test, y_proba), 3))\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1) LEAKY VERSION (WRONG ON PURPOSE)\n",
        "#    - Scaling and feature selection are fit on the FULL dataset\n",
        "#    - THEN we split → information from the test set has leaked into preprocessing\n",
        "# ----------------------------------------------------------------------\n",
        "scaler_leaky   = StandardScaler().fit(X)                     # fit on ALL data\n",
        "X_scaled_leaky = scaler_leaky.transform(X)\n",
        "\n",
        "selector_leaky = SelectKBest(score_func=f_classif, k=10).fit(X_scaled_leaky, y)  # fit on ALL data (uses y! omg)\n",
        "X_sel_leaky    = selector_leaky.transform(X_scaled_leaky)\n",
        "\n",
        "X_train_L, X_test_L, y_train_L, y_test_L = train_test_split(\n",
        "    X_sel_leaky, y, test_size=0.2, stratify=y, random_state=RNG\n",
        ")\n",
        "\n",
        "lr_leaky = LogisticRegression(max_iter=1000, solver=\"lbfgs\", class_weight=\"balanced\", random_state=RNG)\n",
        "evaluate(lr_leaky, X_train_L, X_test_L, y_train_L, y_test_L, name=\"LEAKY workflow\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2) FIXED VERSION (CORRECT)\n",
        "#    - Split first\n",
        "#    - Use a Pipeline so that scaling & feature selection are fit ONLY on train\n",
        "#      and re-fit inside each CV fold (no peeking)\n",
        "# ----------------------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RNG\n",
        ")\n",
        "\n",
        "pipe_clean = Pipeline(steps=[\n",
        "    (\"scaler\",   StandardScaler()),\n",
        "    (\"select\",   SelectKBest(score_func=f_classif, k=10)),\n",
        "    (\"model\",    LogisticRegression(max_iter=1000, solver=\"lbfgs\", class_weight=\"balanced\", random_state=RNG))\n",
        "])\n",
        "\n",
        "evaluate(pipe_clean, X_train, X_test, y_train, y_test, name=\"CLEAN pipeline (k=10)\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3) (Optional) Model selection the RIGHT way (inside CV)\n",
        "#    - Tune k with GridSearchCV + StratifiedKFold\n",
        "#    - All preprocessing is inside the pipeline (no leakage)\n",
        "# ----------------------------------------------------------------------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RNG)\n",
        "\n",
        "param_grid = {\n",
        "    \"select__k\": [5, 10, 15, 20],\n",
        "    \"model__C\":  [0.1, 1.0, 10.0],  # regularization strength\n",
        "    \"model__penalty\": [\"l2\"]        # can add \"l1\" with solver=\"saga\"\n",
        "}\n",
        "\n",
        "pipe_search = Pipeline(steps=[\n",
        "    (\"scaler\",   StandardScaler()),\n",
        "    (\"select\",   SelectKBest(score_func=f_classif)),\n",
        "    (\"model\",    LogisticRegression(max_iter=1000, solver=\"lbfgs\",\n",
        "                                    class_weight=\"balanced\", random_state=RNG))\n",
        "])\n",
        "\n",
        "grid = GridSearchCV(pipe_search, param_grid=param_grid, scoring=\"roc_auc\",\n",
        "                    cv=cv, n_jobs=-1, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest CV params:\", grid.best_params_)\n",
        "print(\"Best CV ROC AUC:\", round(grid.best_score_, 3))\n",
        "\n",
        "# Evaluate best pipeline on held-out test\n",
        "best_model = grid.best_estimator_\n",
        "evaluate(best_model, X_train, X_test, y_train, y_test, name=\"BEST pipeline (CV-tuned)\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Student prompts:\n",
        "# - Where exactly is the leakage in the LEAKY version?\n",
        "# - Why is SelectKBest before the split a bigger problem than scaling?\n",
        "# - Compare AUC and precision/recall between LEAKY vs CLEAN vs BEST.\n",
        "# - If we changed the threshold to maximize F1, how would your confusion matrix change?\n",
        "# ----------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compare & Learn\n",
        "\n",
        "1. Where's the leakage?\n"
      ],
      "metadata": {
        "id": "pgib6EbM48sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Iqqt5gch7q4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. But my LEAKY and CLEAN results are identical - does that mean leakage is harmless?\n"
      ],
      "metadata": {
        "id": "IxbISJA_5UDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uttwn6VQ7tx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What changed from CLEAN to BEST (CV-tuned)? Be precise about FNs (read the confusion matrix), FPs, TNs, and TPs. Look at Recall, F1, Accuracy, and AUC for Class-1. Did they improve or not?\n"
      ],
      "metadata": {
        "id": "bkuMDDA75inK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SGA9GUek7w_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Which error type improved most, and what does that mean in a clinical context?\n"
      ],
      "metadata": {
        "id": "naX3DHa1599r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yTDryDDt7zHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Why did AUC barely move (0.991→0.994) even though recall/F1 improved a lot?\n",
        "\n"
      ],
      "metadata": {
        "id": "bSerFyN_6DPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "54-dS1ny71Lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. If we (incorrectly) do feature selection BEFORE CV, what happens to CV scores vs test scores?\n"
      ],
      "metadata": {
        "id": "r2vcGlza6dbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vNaJa0Id72ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How does the Pipeline stop leakage during CV?\n"
      ],
      "metadata": {
        "id": "cj2RMnds6gog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MqRi3obj74Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Why is leaky feature selection more dangerous than leaky scaling?\n"
      ],
      "metadata": {
        "id": "-SvfliRN61GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5RSBVtmq75_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Given the three reports, which model would you deploy and why?\n",
        "* A: BEST (CV-tuned)—it improves recall/F1 without increasing FP (still 2), and it was selected with leakage-safe CV."
      ],
      "metadata": {
        "id": "BpjavMNU7HgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. If your goal is screening (prioritize recall), what's your next step after BEST?\n"
      ],
      "metadata": {
        "id": "VzV9sDqB65LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ACSa-fy4774P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What single line proves your evaluation is leakage-safe?\n"
      ],
      "metadata": {
        "id": "LRG_g01L6-0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UvPmo8QI7-e5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Name two other common leakage traps to watch for.\n"
      ],
      "metadata": {
        "id": "PXjMT-9b7Lnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p3Mdf_UT8AcA"
      }
    }
  ]
}